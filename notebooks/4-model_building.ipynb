{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39579729",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "In this notebook, I will develop a predictive model to forecast future energy consumption. \n",
    "\n",
    "I will experiment with multiple regression algorithms, compare their performances using standard evaluation metrics (RMSE, MAE, R² Score), and select the best-performing model for deployment. This step is critical to ensure accurate and reliable energy demand forecasting.\n",
    "\n",
    "### Key Steps:\n",
    "- Load processed dataset\n",
    "- Perform time-based train-test split\n",
    "- Train multiple regression models\n",
    "- Evaluate using RMSE, MAE, and R²\n",
    "- Select and save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "434f9960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.6.0)\n",
      "Requirement already satisfied: catboost in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.2.8)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightgbm) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightgbm) (1.15.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (3.10.1)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (2.3.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (6.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24->catboost) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (3.2.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly->catboost) (1.33.0)\n"
     ]
    }
   ],
   "source": [
    "## installing lightgbm and catboost\n",
    "!pip install lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "205ed70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prophet\n",
      "  Downloading prophet-1.1.7-py3-none-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting cmdstanpy>=1.0.4 (from prophet)\n",
      "  Downloading cmdstanpy-1.2.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prophet) (2.2.3)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prophet) (3.10.1)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prophet) (2.3.1)\n",
      "Collecting holidays<1,>=0.25 (from prophet)\n",
      "  Using cached holidays-0.77-py3-none-any.whl.metadata (46 kB)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prophet) (4.67.1)\n",
      "Collecting importlib_resources (from prophet)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Collecting stanio<2.0.0,>=0.4.0 (from cmdstanpy>=1.0.4->prophet)\n",
      "  Downloading stanio-0.5.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (3.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.4->prophet) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Downloading prophet-1.1.7-py3-none-win_amd64.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 3.7/13.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.7/13.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.5/13.3 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.8/13.3 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.6/13.3 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.7/13.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.4/13.3 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.0/13.3 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.3/13.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.3/13.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.1/13.3 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading holidays-0.77-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.8/1.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 1.6 MB/s eta 0:00:00\n",
      "Downloading cmdstanpy-1.2.5-py3-none-any.whl (94 kB)\n",
      "Downloading stanio-0.5.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: stanio, importlib_resources, holidays, cmdstanpy, prophet\n",
      "\n",
      "   -------- ------------------------------- 1/5 [importlib_resources]\n",
      "   -------- ------------------------------- 1/5 [importlib_resources]\n",
      "   -------- ------------------------------- 1/5 [importlib_resources]\n",
      "   -------- ------------------------------- 1/5 [importlib_resources]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ---------------- ----------------------- 2/5 [holidays]\n",
      "   ------------------------ --------------- 3/5 [cmdstanpy]\n",
      "   ------------------------ --------------- 3/5 [cmdstanpy]\n",
      "   ------------------------ --------------- 3/5 [cmdstanpy]\n",
      "   ------------------------ --------------- 3/5 [cmdstanpy]\n",
      "   ------------------------ --------------- 3/5 [cmdstanpy]\n",
      "   -------------------------------- ------- 4/5 [prophet]\n",
      "   -------------------------------- ------- 4/5 [prophet]\n",
      "   -------------------------------- ------- 4/5 [prophet]\n",
      "   -------------------------------- ------- 4/5 [prophet]\n",
      "   -------------------------------- ------- 4/5 [prophet]\n",
      "   -------------------------------- ------- 4/5 [prophet]\n",
      "   -------------------------------- ------- 4/5 [prophet]\n",
      "   ---------------------------------------- 5/5 [prophet]\n",
      "\n",
      "Successfully installed cmdstanpy-1.2.5 holidays-0.77 importlib_resources-6.5.2 prophet-1.1.7 stanio-0.5.1\n"
     ]
    }
   ],
   "source": [
    "## installing prophet\n",
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8ccdb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "# for arima model\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# for prophet\n",
    "from prophet import Prophet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb44795d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "      <th>PJMW_MW</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>PJME_PJMW_avg_Consumption</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-04-01 01:00:00</th>\n",
       "      <td>21734.0</td>\n",
       "      <td>4374.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>13054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-01 02:00:00</th>\n",
       "      <td>20971.0</td>\n",
       "      <td>4306.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12638.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-01 03:00:00</th>\n",
       "      <td>20721.0</td>\n",
       "      <td>4322.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12521.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-01 04:00:00</th>\n",
       "      <td>20771.0</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-01 05:00:00</th>\n",
       "      <td>21334.0</td>\n",
       "      <td>4436.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12885.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PJME_MW  PJMW_MW  hour  dayofweek  quarter  month  year  \\\n",
       "Datetime                                                                       \n",
       "2002-04-01 01:00:00  21734.0   4374.0     1          0        2      4  2002   \n",
       "2002-04-01 02:00:00  20971.0   4306.0     2          0        2      4  2002   \n",
       "2002-04-01 03:00:00  20721.0   4322.0     3          0        2      4  2002   \n",
       "2002-04-01 04:00:00  20771.0   4359.0     4          0        2      4  2002   \n",
       "2002-04-01 05:00:00  21334.0   4436.0     5          0        2      4  2002   \n",
       "\n",
       "                     dayofyear  dayofmonth  weekofyear  is_holiday  \\\n",
       "Datetime                                                             \n",
       "2002-04-01 01:00:00         91           1          14           0   \n",
       "2002-04-01 02:00:00         91           1          14           0   \n",
       "2002-04-01 03:00:00         91           1          14           0   \n",
       "2002-04-01 04:00:00         91           1          14           0   \n",
       "2002-04-01 05:00:00         91           1          14           0   \n",
       "\n",
       "                     PJME_PJMW_avg_Consumption  \n",
       "Datetime                                        \n",
       "2002-04-01 01:00:00                    13054.0  \n",
       "2002-04-01 02:00:00                    12638.5  \n",
       "2002-04-01 03:00:00                    12521.5  \n",
       "2002-04-01 04:00:00                    12565.0  \n",
       "2002-04-01 05:00:00                    12885.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading the dataset\n",
    "df_final = pd.read_parquet(r\"C:\\Users\\himan\\Desktop\\Projects\\Energy_Forecasting_System\\data\\processed-data\\est_hourly_cleaned_with_features.parquet\")\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026214b",
   "metadata": {},
   "source": [
    "Now its time to split the data into \"train\" for training the model and \"test\" for testing it on the model. But unlike other cases where we split the data randomly, in time-series tasks, we need to take care that we only want to train our model on past data and test on the future data. This can prevent data leakage.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "010bcf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting the data into train and test\n",
    "test_size = 0.8\n",
    "split_range = int(test_size * len(df_final))  ## 0.8 * x can give us float value which will give us an error in train-test split. So we make sure that it returns only int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b05c20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_pjme = df_final.drop([\"PJME_MW\"] , axis = 1)\\nX_pjmw = df_final.drop([\"PJMW_MW\"] , axis = 1)\\n\\ny_pjme = df_final[\"PJME_MW\"]\\ny_pjmw = df_final[\"PJMW_MW\"]'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## defining target variable\n",
    "\"\"\"X_pjme = df_final.drop([\"PJME_MW\"] , axis = 1)\n",
    "X_pjmw = df_final.drop([\"PJMW_MW\"] , axis = 1)\n",
    "\n",
    "y_pjme = df_final[\"PJME_MW\"]\n",
    "y_pjmw = df_final[\"PJMW_MW\"]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81a63f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train_pjme, X_test_pjme = X_pjme.iloc[:split_range], X_pjme.iloc[split_range:]\\ny_train_pjme, y_test_pjme = y_pjme.iloc[:split_range], y_pjme.iloc[split_range:]\\n\\nX_train_pjmw, X_test_pjmw = X_pjmw.iloc[:split_range], X_pjmw.iloc[split_range:]\\ny_train_pjmw, y_test_pjmw = y_pjmw.iloc[:split_range], y_pjmw.iloc[split_range:]'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Time-based Train-Test split\n",
    "\"\"\"X_train_pjme, X_test_pjme = X_pjme.iloc[:split_range], X_pjme.iloc[split_range:]\n",
    "y_train_pjme, y_test_pjme = y_pjme.iloc[:split_range], y_pjme.iloc[split_range:]\n",
    "\n",
    "X_train_pjmw, X_test_pjmw = X_pjmw.iloc[:split_range], X_pjmw.iloc[split_range:]\n",
    "y_train_pjmw, y_test_pjmw = y_pjmw.iloc[:split_range], y_pjmw.iloc[split_range:]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f43b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing metrices\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "161486a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating function to evalueate model\n",
    "import numpy as np\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b5e3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## our models\n",
    "models = {\n",
    "    \"XGBoost\": XGBRegressor(),\n",
    "    \"Decision Tree\" : DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"LightGBM\": LGBMRegressor(),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"K-Neighbors\": KNeighborsRegressor(),\n",
    "    \"Elastic Net\": ElasticNet(),\n",
    "    \"SARIMA\" : SARIMAX,\n",
    "    \"ARIMA\": ARIMA,\n",
    "    \"Prophet\": Prophet()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f29290",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'PJME': {\n",
    "        'X': df_final.drop([\"PJME_MW\", \"PJME_PJMW_avg_Consumption\"], axis=1),\n",
    "        'y': df_final[\"PJME_MW\"]\n",
    "    },\n",
    "    'PJMW': {\n",
    "        'X': df_final.drop([\"PJMW_MW\", \"PJME_PJMW_avg_Consumption\"], axis=1),\n",
    "        'y': df_final[\"PJMW_MW\"]\n",
    "    },\n",
    "    'Average': {\n",
    "        'X': df_final.drop([\"PJME_MW\", \"PJMW_MW\", \"PJME_PJMW_avg_Consumption\"], axis=1),\n",
    "        'y': df_final[\"PJME_PJMW_avg_Consumption\"]  \n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3ea532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\himan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 114571, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 32348.251739\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.22 GiB for an array with shape (114571, 51, 51) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     22\u001b[39m sarima_model = SARIMAX(y_train,\n\u001b[32m     23\u001b[39m                        order=(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m),  \u001b[38;5;66;03m# p, d, q values (adjust as necessary)\u001b[39;00m\n\u001b[32m     24\u001b[39m                        seasonal_order=(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m24\u001b[39m),  \u001b[38;5;66;03m# P, D, Q, S for daily seasonality\u001b[39;00m\n\u001b[32m     25\u001b[39m                        enforce_stationarity=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     26\u001b[39m                        enforce_invertibility=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Fit the SARIMA model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m sarima_fitted = \u001b[43msarima_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Predict on the test data\u001b[39;00m\n\u001b[32m     31\u001b[39m predictions_sarima = sarima_fitted.predict(start=\u001b[38;5;28mlen\u001b[39m(y_train), end=\u001b[38;5;28mlen\u001b[39m(y_train) + \u001b[38;5;28mlen\u001b[39m(y_test) - \u001b[32m1\u001b[39m, dynamic=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:729\u001b[39m, in \u001b[36mMLEModel.fit\u001b[39m\u001b[34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    728\u001b[39m     func = \u001b[38;5;28mself\u001b[39m.smooth\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlefit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincludes_fixed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m           \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    732\u001b[39m res.mlefit = mlefit\n\u001b[32m    733\u001b[39m res.mle_retvals = mlefit.mle_retvals\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:890\u001b[39m, in \u001b[36mMLEModel.smooth\u001b[39m\u001b[34m(self, params, transformed, includes_fixed, complex_step, cov_type, cov_kwds, return_ssm, results_class, results_wrapper_class, **kwargs)\u001b[39m\n\u001b[32m    887\u001b[39m result = \u001b[38;5;28mself\u001b[39m.ssm.smooth(complex_step=complex_step, **kwargs)\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Wrap in a results object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_ssm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mresults_wrapper_class\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:789\u001b[39m, in \u001b[36mMLEModel._wrap_results\u001b[39m\u001b[34m(self, params, result, return_raw, cov_type, cov_kwds, results_class, wrapper_class)\u001b[39m\n\u001b[32m    786\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wrapper_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    787\u001b[39m         wrapper_class = \u001b[38;5;28mself\u001b[39m._res_classes[\u001b[33m'\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     res = \u001b[43mresults_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    790\u001b[39m     result = wrapper_class(res)\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1809\u001b[39m, in \u001b[36mSARIMAXResults.__init__\u001b[39m\u001b[34m(self, model, params, filter_results, cov_type, **kwargs)\u001b[39m\n\u001b[32m   1807\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, params, filter_results, cov_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1808\u001b[39m              **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1809\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1811\u001b[39m     \u001b[38;5;28mself\u001b[39m.df_resid = np.inf  \u001b[38;5;66;03m# attribute required for wald tests\u001b[39;00m\n\u001b[32m   1813\u001b[39m     \u001b[38;5;66;03m# Save _init_kwds\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:2495\u001b[39m, in \u001b[36mMLEResults.__init__\u001b[39m\u001b[34m(self, model, params, results, cov_type, cov_kwds, **kwargs)\u001b[39m\n\u001b[32m   2492\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m use_pandas:\n\u001b[32m   2493\u001b[39m     tmp = np.transpose(\u001b[38;5;28mself\u001b[39m.smoothed_state_cov, (\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m   2494\u001b[39m     \u001b[38;5;28mself\u001b[39m._states.smoothed_cov = pd.DataFrame(\n\u001b[32m-> \u001b[39m\u001b[32m2495\u001b[39m         \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2496\u001b[39m         index=pd.MultiIndex.from_product([index, columns]).swaplevel(),\n\u001b[32m   2497\u001b[39m         columns=columns)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2499\u001b[39m     \u001b[38;5;28mself\u001b[39m._states.smoothed_cov = np.transpose(\n\u001b[32m   2500\u001b[39m         \u001b[38;5;28mself\u001b[39m.smoothed_state_cov, (\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:324\u001b[39m, in \u001b[36mreshape\u001b[39m\u001b[34m(a, shape, order, newshape, copy)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[33m'\u001b[39m\u001b[33mreshape\u001b[39m\u001b[33m'\u001b[39m, shape, order=order, copy=copy)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreshape\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 2.22 GiB for an array with shape (114571, 51, 51) and data type float64"
     ]
    }
   ],
   "source": [
    "## Initialize result storage for models\n",
    "results = {}\n",
    "\n",
    "## Define the test size split\n",
    "test_size = 0.8\n",
    "split_range = int(test_size * len(df_final))\n",
    "\n",
    "for target_name, data in data_dict.items():\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test = X.iloc[:split_range], X.iloc[split_range:]\n",
    "    y_train, y_test = y.iloc[:split_range], y.iloc[split_range:]\n",
    "\n",
    "    result_target = []\n",
    "\n",
    "    ## Iterate through the models\n",
    "    for model_name, model in models.items():\n",
    "        if model_name == \"SARIMA\":\n",
    "            ## SARIMA model\n",
    "            sarima_model = SARIMAX(y_train,\n",
    "                                   order=(1, 1, 1),  # p, d, q values (adjust as necessary)\n",
    "                                   seasonal_order=(1, 1, 1, 24),  # P, D, Q, S for daily seasonality\n",
    "                                   enforce_stationarity=False,\n",
    "                                   enforce_invertibility=False)\n",
    "            ## Fit the SARIMA model\n",
    "            sarima_fitted = sarima_model.fit(disp=False)\n",
    "\n",
    "            ## Predict on the test data\n",
    "            predictions_sarima = sarima_fitted.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1, dynamic=False)\n",
    "\n",
    "            ## Evaluating the performance of the SARIMA model\n",
    "            train_metrices_sarima = evaluate_model(y_train, predictions_sarima[:len(y_train)])\n",
    "            test_metrices_sarima = evaluate_model(y_test, predictions_sarima[len(y_train):])\n",
    "\n",
    "            ## Store results for SARIMA\n",
    "            result_target.append({\n",
    "                'Model': model_name,\n",
    "                'Train_RMSE': train_metrices_sarima[2],\n",
    "                'Test_RMSE': test_metrices_sarima[2],\n",
    "                'Train_R2': train_metrices_sarima[3],\n",
    "                'Test_R2': test_metrices_sarima[3]\n",
    "            })\n",
    "        \n",
    "        else:\n",
    "            ## For other models (XGBoost, Random Forest, etc.)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            ## Predict on the training and test sets\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            ## Evaluating the model\n",
    "            train_metrices = evaluate_model(y_train, y_train_pred)\n",
    "            test_metrices = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "            ## Store results for other models\n",
    "            result_target.append({\n",
    "                'Model': model_name,\n",
    "                'Train_RMSE': train_metrices[2],\n",
    "                'Test_RMSE': test_metrices[2],\n",
    "                'Train_R2': train_metrices[3],\n",
    "                'Test_R2': test_metrices[3]\n",
    "            })\n",
    "    \n",
    "    ## Add the results for the current target variable (PJME, PJMW, Average)\n",
    "    results.append({\n",
    "        'Target': target_name,\n",
    "        'Results': result_target\n",
    "    })\n",
    "\n",
    "## Convert results into a DataFrame for better visualization\n",
    "results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0bdcaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>Train_R2</th>\n",
       "      <th>Test_R2</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1010.479570</td>\n",
       "      <td>1815.091392</td>\n",
       "      <td>0.975558</td>\n",
       "      <td>0.922046</td>\n",
       "      <td>PJME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>2.422571</td>\n",
       "      <td>2259.956295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879151</td>\n",
       "      <td>PJME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>365.522940</td>\n",
       "      <td>1805.646018</td>\n",
       "      <td>0.996802</td>\n",
       "      <td>0.922855</td>\n",
       "      <td>PJME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>155.527193</td>\n",
       "      <td>289.999553</td>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.914982</td>\n",
       "      <td>PJMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.124083</td>\n",
       "      <td>361.878317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867613</td>\n",
       "      <td>PJMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>56.252670</td>\n",
       "      <td>273.107572</td>\n",
       "      <td>0.996670</td>\n",
       "      <td>0.924597</td>\n",
       "      <td>PJMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>972.206337</td>\n",
       "      <td>2536.107815</td>\n",
       "      <td>0.929623</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.212873</td>\n",
       "      <td>2878.551652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.394934</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>267.839692</td>\n",
       "      <td>2606.987918</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.503713</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model   Train_RMSE    Test_RMSE  Train_R2   Test_R2   Target\n",
       "0        XGBoost  1010.479570  1815.091392  0.975558  0.922046     PJME\n",
       "1  Decision Tree     2.422571  2259.956295  1.000000  0.879151     PJME\n",
       "2  Random Forest   365.522940  1805.646018  0.996802  0.922855     PJME\n",
       "3        XGBoost   155.527193   289.999553  0.974545  0.914982     PJMW\n",
       "4  Decision Tree     0.124083   361.878317  1.000000  0.867613     PJMW\n",
       "5  Random Forest    56.252670   273.107572  0.996670  0.924597     PJMW\n",
       "6        XGBoost   972.206337  2536.107815  0.929623  0.530333  Average\n",
       "7  Decision Tree     1.212873  2878.551652  1.000000  0.394934  Average\n",
       "8  Random Forest   267.839692  2606.987918  0.994659  0.503713  Average"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of our models\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for target_name, result in results.items():\n",
    "    temp_df = pd.DataFrame(result)\n",
    "    temp_df['Target'] = target_name\n",
    "    results_df = pd.concat([results_df, temp_df], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770e617",
   "metadata": {},
   "source": [
    "### Training on SARIMA - Seasonal ARIMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fbf1719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\himan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\himan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 643. MiB for an array with shape (51, 51, 32378) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      4\u001b[39m sarima_model = SARIMAX(y_train,\n\u001b[32m      5\u001b[39m                        order=(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m),  \u001b[38;5;66;03m# p, d, q values (adjust as necessary)\u001b[39;00m\n\u001b[32m      6\u001b[39m                        seasonal_order=(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m24\u001b[39m),  \u001b[38;5;66;03m# P, D, Q, S for daily seasonality\u001b[39;00m\n\u001b[32m      7\u001b[39m                        enforce_stationarity=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      8\u001b[39m                        enforce_invertibility=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     10\u001b[39m sarima_fitted = sarima_model.fit(disp=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m predictions_sarima = \u001b[43msarima_fitted\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Evaluate the performance of the model\u001b[39;00m\n\u001b[32m     15\u001b[39m train_metrices_sarima = evaluate_model(y_train, y_train_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\wrapper.py:113\u001b[39m, in \u001b[36mmake_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m     obj = data.wrap_output(func(results, *args, **kwargs), how[\u001b[32m0\u001b[39m], how[\u001b[32m1\u001b[39m:])\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m how:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     obj = data.wrap_output(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, how)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3488\u001b[39m, in \u001b[36mMLEResults.predict\u001b[39m\u001b[34m(self, start, end, dynamic, information_set, signal_only, **kwargs)\u001b[39m\n\u001b[32m   3423\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3424\u001b[39m \u001b[33;03mIn-sample prediction and out-of-sample forecasting\u001b[39;00m\n\u001b[32m   3425\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3485\u001b[39m \u001b[33;03m    including confidence intervals.\u001b[39;00m\n\u001b[32m   3486\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3487\u001b[39m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3488\u001b[39m prediction_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43minformation_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3490\u001b[39m \u001b[43m    \u001b[49m\u001b[43msignal_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignal_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3491\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_results.predicted_mean\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3366\u001b[39m, in \u001b[36mMLEResults.get_prediction\u001b[39m\u001b[34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[39m\n\u001b[32m   3361\u001b[39m \u001b[38;5;28mself\u001b[39m.model.update(\u001b[38;5;28mself\u001b[39m.params, transformed=\u001b[38;5;28;01mTrue\u001b[39;00m, includes_fixed=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   3363\u001b[39m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[32m   3364\u001b[39m \u001b[38;5;66;03m# This is a (k_endog x npredictions) array; do not want to squeeze in\u001b[39;00m\n\u001b[32m   3365\u001b[39m \u001b[38;5;66;03m# case of npredictions = 1\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3366\u001b[39m prediction_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilter_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_of_sample\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3369\u001b[39m \u001b[38;5;66;03m# Return a new mlemodel.PredictionResults object\u001b[39;00m\n\u001b[32m   3370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResultsWrapper(PredictionResults(\n\u001b[32m   3371\u001b[39m     \u001b[38;5;28mself\u001b[39m, prediction_results, information_set=information_set,\n\u001b[32m   3372\u001b[39m     signal_only=signal_only, row_labels=prediction_index))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:2096\u001b[39m, in \u001b[36mFilterResults.predict\u001b[39m\u001b[34m(self, start, end, dynamic, **kwargs)\u001b[39m\n\u001b[32m   2093\u001b[39m         model.endog[:, -(ndynamic + nforecast):] = np.nan\n\u001b[32m   2095\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m model.fixed_scale(\u001b[38;5;28mself\u001b[39m.scale):\n\u001b[32m-> \u001b[39m\u001b[32m2096\u001b[39m         oos_results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2098\u001b[39m     results = \u001b[38;5;28mself\u001b[39m\n\u001b[32m   2100\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResults(results, start, end, nstatic, ndynamic,\n\u001b[32m   2101\u001b[39m                          nforecast, oos_results=oos_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:977\u001b[39m, in \u001b[36mKalmanFilter.filter\u001b[39m\u001b[34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[39m\n\u001b[32m    975\u001b[39m results = \u001b[38;5;28mself\u001b[39m.results_class(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    976\u001b[39m results.update_representation(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m977\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkfilter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[38;5;66;03m# Resent memory conservation\u001b[39;00m\n\u001b[32m    980\u001b[39m \u001b[38;5;28mself\u001b[39m.set_conserve_memory(conserve_memory_cache)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:1539\u001b[39m, in \u001b[36mFilterResults.update_filter\u001b[39m\u001b[34m(self, kalman_filter)\u001b[39m\n\u001b[32m   1535\u001b[39m \u001b[38;5;28mself\u001b[39m.univariate_filter = np.array(kalman_filter.univariate_filter,\n\u001b[32m   1536\u001b[39m                                   copy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1538\u001b[39m \u001b[38;5;28mself\u001b[39m.filtered_state = np.array(kalman_filter.filtered_state, copy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1539\u001b[39m \u001b[38;5;28mself\u001b[39m.filtered_state_cov = np.array(\n\u001b[32m   1540\u001b[39m     kalman_filter.filtered_state_cov, copy=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1541\u001b[39m )\n\u001b[32m   1542\u001b[39m \u001b[38;5;28mself\u001b[39m.predicted_state = np.array(\n\u001b[32m   1543\u001b[39m     kalman_filter.predicted_state, copy=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1544\u001b[39m )\n\u001b[32m   1545\u001b[39m \u001b[38;5;28mself\u001b[39m.predicted_state_cov = np.array(\n\u001b[32m   1546\u001b[39m     kalman_filter.predicted_state_cov, copy=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1547\u001b[39m )\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 643. MiB for an array with shape (51, 51, 32378) and data type float64"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "df_sarima = df_cleaned[['PJM_Load']]\n",
    "# Fit the SARIMA model (adjust the parameters based on your data, p,d,q, seasonal_order)\n",
    "sarima_model = SARIMAX(y_train,\n",
    "                       order=(1, 1, 1),  # p, d, q values (adjust as necessary)\n",
    "                       seasonal_order=(1, 1, 1, 24),  # P, D, Q, S for daily seasonality\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False)\n",
    "\n",
    "sarima_fitted = sarima_model.fit(disp=False)\n",
    "\n",
    "predictions_sarima = sarima_fitted.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1, dynamic=False)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "train_metrices_sarima = evaluate_model(y_train, y_train_pred)\n",
    "test_metrices_sarima = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "result.append({\n",
    "    'Model': model_name,\n",
    "    'Train_RMSE': train_metrices[2],\n",
    "    'Test_RMSE': test_metrices[2],\n",
    "    'Train_R2': train_metrices[3],\n",
    "    'Test_R2': test_metrices[3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f856bf3",
   "metadata": {},
   "source": [
    "### Training on SARIMAX - Seasonal ARIMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\himan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "X = df_cleaned[['AEP', 'COMED', 'DAYTON']]\n",
    "df_sarima = df_cleaned[['PJM_Load']]\n",
    "\n",
    "# Fit the SARIMAX model with exogenous variables\n",
    "sarimax_model = SARIMAX(y_train,\n",
    "                        exog=X_train,\n",
    "                        order=(1, 1, 1),  # p, d, q values (adjust as necessary)\n",
    "                        seasonal_order=(1, 1, 1, 24),  # P, D, Q, S for daily seasonality\n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False)\n",
    "\n",
    "sarimax_fitted = sarimax_model.fit(disp=False)\n",
    "\n",
    "predictions_sarimax = sarimax_fitted.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1, exog=X_test, dynamic=False)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "train_metrices_sarimax = evaluate_model(y_train, y_train_pred)\n",
    "test_metrices_sarimax = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "result.append({\n",
    "    'Model': model_name,\n",
    "    'Train_RMSE': train_metrices[2],\n",
    "    'Test_RMSE': test_metrices[2],\n",
    "    'Train_R2': train_metrices[3],\n",
    "    'Test_R2': test_metrices[3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2326dea",
   "metadata": {},
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "\n",
    "\n",
    "prophet_data = df_cleaned[['PJM_Load']].reset_index()\n",
    "prophet_data.columns = ['ds', 'y']  # 'ds' is the datetime column, 'y' is the target variable\n",
    "\n",
    "# Initialize the Prophet model\n",
    "prophet_model = Prophet(daily_seasonality=True, yearly_seasonality=True, seasonality_mode='multiplicative')\n",
    "\n",
    "# Fit the model\n",
    "prophet_model.fit(prophet_data)\n",
    "\n",
    "# Make predictions (for next 24 hours as an example)\n",
    "future = prophet_model.make_future_dataframe(prophet_data, periods=24, freq='H')  # 24 hours ahead\n",
    "forecast = prophet_model.predict(future)\n",
    "\n",
    "# Evaluate the performance\n",
    "prophet_predictions = forecast['yhat'][-len(y_test):].values  # Get the predictions for test period\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "train_metrices_sarimax = evaluate_model(y_train, y_train_pred)\n",
    "test_metrices_sarimax = evaluate_model(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9cb90aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  Train_RMSE  Test_RMSE  Train_R2  Test_R2\n",
      "0            Decision Tree    0.000000        0.0  1.000000      1.0\n",
      "1  Random Forest Regressor  146.288107        0.0  0.997468      1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(result)\n",
    "results_df = results_df.sort_values(by='Test_RMSE')\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b573a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
